{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0be7b61",
   "metadata": {},
   "source": [
    "# TAREFA DATASET KAGGLE\n",
    "\n",
    "\n",
    "Para esta fase, o objetivo é alcançar o melhor resultado possível com o dataset da competição fornecido pelos docentes na previsão do nível de incidentes rodoviários, numa determinada hora, na cidade de Guimarães."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3425fbd",
   "metadata": {},
   "source": [
    "### **1.** Importar as bibliotecas essenciais do Python para a elaboração desta tarefa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2110514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e69e0",
   "metadata": {},
   "source": [
    "### **2.** Carregar o dataset para um dataframe da biblioteca Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('docs/training_data.csv', encoding=\"utf-8\", skipinitialspace=True)\n",
    "df_teste = pd.read_csv('docs/test_data.csv', encoding=\"utf-8\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67994d89",
   "metadata": {},
   "source": [
    "### **3.** Obtenção de informação acerca do dataset: tipos de dados das features, conteúdo do dataset e estatística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d0507",
   "metadata": {},
   "source": [
    "* **tipos de dados das features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5152fce",
   "metadata": {},
   "source": [
    "* **conteúdo do dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561aa58",
   "metadata": {},
   "source": [
    "* **estatística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d441b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00787f",
   "metadata": {},
   "source": [
    "Distribuição da feature target \"incidents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be961c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"incidents\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc82c89",
   "metadata": {},
   "source": [
    "Análise dos valores únicos no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d4274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in df:\n",
    "    print(f\"{c}: {df[c].unique()}\")\n",
    "    print(f\"Quantidade: {df[c].nunique()}\")\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54e250",
   "metadata": {},
   "source": [
    "TODO: tabelinha gira da análise da tabela acima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df88f51",
   "metadata": {},
   "source": [
    "### **4.** Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58452eaf",
   "metadata": {},
   "source": [
    "**Remoção da feature \"avg_precipitation\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ee45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Possui informação incompleta\n",
    "df = df.drop('avg_precipitation', axis=1)\n",
    "df_teste = df_teste.drop('avg_precipitation', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10bf98",
   "metadata": {},
   "source": [
    "**Transformação da coluna *record_date* nas colunas ano, mês, dia, hora e minuto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5c906-af4a-40db-8d3b-2a1122a34248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['record_date'] = pd.to_datetime(df['record_date'],format='%Y-%m-%d %H:%M', errors='coerce')\n",
    "assert df['record_date'].isnull().sum() == 0,'missing record date'\n",
    "\n",
    "df['record_date_year'] = df['record_date'].dt.year\n",
    "df['record_date_month'] = df['record_date'].dt.month\n",
    "df['record_date_day'] = df['record_date'].dt.day\n",
    "df['record_date_hour'] = df['record_date'].dt.hour\n",
    "df['record_date_minute'] = df['record_date'].dt.minute\n",
    "df = df.drop('record_date', axis=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "df_teste['record_date'] = pd.to_datetime(df_teste['record_date'],format='%Y-%m-%d %H:%M', errors='coerce')\n",
    "assert df_teste['record_date'].isnull().sum() == 0,'missing record date'\n",
    "\n",
    "df_teste['record_date_year'] = df_teste['record_date'].dt.year\n",
    "df_teste['record_date_month'] = df_teste['record_date'].dt.month\n",
    "df_teste['record_date_day'] = df_teste['record_date'].dt.day\n",
    "df_teste['record_date_hour'] = df_teste['record_date'].dt.hour\n",
    "df_teste['record_date_minute'] = df_teste['record_date'].dt.minute\n",
    "df_teste = df_teste.drop('record_date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87d239",
   "metadata": {},
   "source": [
    "**Remoção das features \"city_name\", \"record_date_year\" e \"record_date_minute\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac48a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#como apenas existe um valor para \"city_name\", esta coluna pode ser removida\n",
    "df = df.drop('city_name', axis=1)\n",
    "df_teste = df_teste.drop('city_name', axis=1)\n",
    "\n",
    "#o mesmo se aplica para o ano e minuto\n",
    "df = df.drop('record_date_year', axis=1)\n",
    "df = df.drop('record_date_minute', axis=1)\n",
    "\n",
    "df_teste = df_teste.drop('record_date_year', axis=1)\n",
    "df_teste = df_teste.drop('record_date_minute', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b66e9",
   "metadata": {},
   "source": [
    "**Transformação da feature \"magnitude_of_delay\" em valores numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b38ae-4061-40c5-952d-6939028da932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['magnitude_of_delay'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb417e1-69bc-4c14-84ac-d07124720bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'magnitude_of_delay': {'UNDEFINED':0 ,'MODERATE': 1, 'MAJOR': 2}}\n",
    "df.replace(replace_map,inplace=True)\n",
    "df_teste.replace(replace_map,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada91d3",
   "metadata": {},
   "source": [
    "**Tratamento da feature \"affected_roads\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2538c",
   "metadata": {},
   "source": [
    "* Tratamento dos missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['affected_roads'].fillna(',',inplace=True) #tratar de missing values\n",
    "df_teste['affected_roads'].fillna(',',inplace=True) #tratar de missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed21b36b",
   "metadata": {},
   "source": [
    "* Separação das ruas e remoção de ruas repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1f017-eacb-42c4-b7a1-d5520ac4c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_roads = {}\n",
    "\n",
    "#Separação das ruas e remoção de ruas repetidas\n",
    "for row in df['affected_roads']:\n",
    "    roads = list(dict.fromkeys(row.split(',')))\n",
    "    for road in roads:\n",
    "        affected_roads[road] = []\n",
    "\n",
    "for row in df['affected_roads']:\n",
    "    roads = list(dict.fromkeys(row.split(',')))\n",
    "    for road in affected_roads:\n",
    "        if road in roads:\n",
    "            affected_roads[road].append(1)\n",
    "        else:\n",
    "            affected_roads[road].append(0)\n",
    "\n",
    "        \n",
    "affected_roads = pd.DataFrame.from_dict(affected_roads)\n",
    "df = df.drop('affected_roads',axis=1)\n",
    "\n",
    "for column in affected_roads:\n",
    "    df[column] = affected_roads[column]\n",
    "    \n",
    "#######################################################################\n",
    "affected_roads = {}\n",
    "\n",
    "for row in df_teste['affected_roads']:\n",
    "    roads = list(dict.fromkeys(row.split(',')))\n",
    "    for road in roads:\n",
    "        affected_roads[road] = []\n",
    "\n",
    "for row in df_teste['affected_roads']:\n",
    "    roads = list(dict.fromkeys(row.split(',')))\n",
    "    for road in affected_roads:\n",
    "        if road in roads:\n",
    "            affected_roads[road].append(1)\n",
    "        else:\n",
    "            affected_roads[road].append(0)\n",
    "\n",
    "        \n",
    "affected_roads = pd.DataFrame.from_dict(affected_roads)\n",
    "df_teste = df_teste.drop('affected_roads',axis=1)\n",
    "\n",
    "for column in affected_roads:\n",
    "    df_teste[column] = affected_roads[column]\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a789ac6",
   "metadata": {},
   "source": [
    "**Transformação da feature \"luminosity\" em valores numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255298c8-7958-45d3-8072-88265056e73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['luminosity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1eb6a-f931-4e42-b192-25143c58212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'luminosity': {'LOW_LIGHT':0 ,'LIGHT': 1, 'DARK': 2}}\n",
    "df.replace(replace_map,inplace=True)\n",
    "df_teste.replace(replace_map,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07f81a",
   "metadata": {},
   "source": [
    "**Tranformação da feature \"avg_rain\" em valores numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be99b42-acb3-4bff-9570-ce90fce273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4801902-4957-47ec-a34a-cf347acfb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'avg_rain': {'Sem Chuva':0 ,'chuva fraca': 1, 'chuva moderada': 2,'chuva forte' : 3}}\n",
    "df.replace(replace_map,inplace=True)\n",
    "df_teste.replace(replace_map,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dd738",
   "metadata": {},
   "source": [
    "**Transformação da feature \"incidents\" em valores numéricos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e249962-1a4c-4c5e-8b31-9db5a90c5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'incidents': {'None':0 ,'Low': 1, 'Medium': 2, 'High': 3, 'Very_High': 4}}\n",
    "df.replace(replace_map,inplace=True)\n",
    "df_teste.replace(replace_map,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b8ead",
   "metadata": {},
   "source": [
    "#### Adição de feature \"dayOfWeek\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c27c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def getDayofWeek(df):\n",
    "    mes = int (df['record_date_month'])\n",
    "    dia = int (df['record_date_day'])\n",
    "    intDay = datetime.date(year=2021, month=mes, day=dia).weekday()\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    return days[intDay]\n",
    "\n",
    "df['dayOfWeek'] = df.apply(getDayofWeek, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7279a9",
   "metadata": {},
   "source": [
    "### 5. Aplicação de modelos de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5507c",
   "metadata": {},
   "source": [
    "#### 5.1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7949fcf",
   "metadata": {},
   "source": [
    "Imports necessários para a implementação deste modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472fb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"incidents\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83652314",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbfd68",
   "metadata": {},
   "source": [
    "Treino do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=2022)\n",
    "clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd8eca",
   "metadata": {},
   "source": [
    "Visualização da árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c1c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(clf,\n",
    "                     out_file=\"tree_dsCompeticao.dot\",\n",
    "                     filled = True)\n",
    "\n",
    "from graphviz import Source\n",
    "Source.from_file(\"tree_dsCompeticao.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd404095",
   "metadata": {},
   "source": [
    "Geração de previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)\n",
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dab2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be26a3",
   "metadata": {},
   "source": [
    "Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384efebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c05709",
   "metadata": {},
   "source": [
    "**Geração do ficheiro de submissão para o Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função genérica que irá ser reutilizada para os proximos modelos\n",
    "def download_submission_file(model, df_teste, filename):\n",
    "    predictions_dfT = model.predict(df_teste)\n",
    "    pd.DataFrame(predictions_dfT)\n",
    "    \n",
    "    replace_map = {'Incidents': {\"0\":'None' ,\"1\":'Low', \"2\":'Medium', \"3\":'High', \"4\":'Very_High'}}\n",
    "    \n",
    "    predictions_dfT = pd.DataFrame(predictions_dfT, columns = [\"Incidents\"])\n",
    "    predictions_dfT[\"Incidents\"] = predictions_dfT[\"Incidents\"].astype(str)\n",
    "    predictions_dfT.replace(replace_map,inplace=True)\n",
    "    predictions_dfT.index+=1\n",
    "    predictions_dfT.head()\n",
    "    \n",
    "    from pathlib import Path\n",
    "    filepath = Path(filename)\n",
    "    predictions_dfT.to_csv(filepath, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_submission_file(clf, df_teste, \"submission_files/decisionTree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3694869e",
   "metadata": {},
   "source": [
    "#### 5.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2879d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90795f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['incidents'], axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e28fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['incidents']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(x)\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(y)\n",
    "x_scaled = pd.DataFrame(scaler_X.transform(x[x.columns]), columns=x.columns)\n",
    "y_scaled = pd.DataFrame(scaler_y.transform(y[y.columns]), columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(x_scaled,y_scaled,test_size=0.25,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver=\"newton-cg\", random_state=2022) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'incidents': {\"0.0\":'None' ,\"0.25\":'Low', \"0.5\":'Medium', \"0.75\":'High', \"1.0\":'Very_High'}}\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns = [\"incidents\"])\n",
    "y_train[\"incidents\"] = y_train[\"incidents\"].astype(str)\n",
    "y_train.replace(replace_map,inplace=True)\n",
    "y_train.index+=1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67800a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b01f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_submission_file(lr, df_teste, \"submission_files/logisticRegression.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0fa84",
   "metadata": {},
   "source": [
    "#### 5.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['incidents'], axis=1)\n",
    "\n",
    "y = df['incidents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471f9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(random_state=2022)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_submission_file(model, df_teste, \"submission_files/svm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b2bd5-8e3f-4b0b-b66d-aafab1dd17da",
   "metadata": {},
   "source": [
    "#### 5.4 Redes neuronais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba9f004-13a2-4c71-bcda-2e56b399a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501adab-5de3-433e-a79e-eb85ff51096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('incidents',axis=1)\n",
    "y = df[['incidents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b194fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(x)\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(y)\n",
    "x_scaled = pd.DataFrame(scaler_X.transform(x[x.columns]), columns=x.columns)\n",
    "y_scaled = pd.DataFrame(scaler_y.transform(y[y.columns]), columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8edf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled,test_size=0.2,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ac96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation = \"relu\", learning_rate = 0.01):\n",
    "    #Create a sequential model (with three layers - last one is the output)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim = 5, activation = activation))\n",
    "    model.add(Dense(8, activation = activation))\n",
    "    model.add(Dense(1, activation = \"relu\"))\n",
    "    \n",
    "    #Compile the model\n",
    "    #Define the loss function, the otimizer and metrics to be used\n",
    "    model.compile(\n",
    "        loss = \"mae\",\n",
    "        optimizer = optimizers.Adam(learning_rate),\n",
    "        metrics = [\"mae\", \"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c225d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d414af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_DICT = {\n",
    "    \"activation\" :    [\"relu\", \"sigmoid\"],\n",
    "    \"learning_rate\" : [0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b654c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 2022)\n",
    "\n",
    "model = KerasRegressor(build_fn = build_model, epochs = 20, batch_size = 32)\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                           param_grid = TUNING_DICT,\n",
    "                           cv = kf,\n",
    "                           scoring = \"neg_mean_absolute_error\",\n",
    "                           refit = \"True\",\n",
    "                           verbose = 1)\n",
    "\n",
    "grid_search.fit(x_train, y_train, validation_split = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize results\n",
    "print(\"Best: %f using %s\" %(grid_search.best_score_, grid_search.best_params_))\n",
    "means = grid_search.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search.cv_results_[\"std_test_score\"]\n",
    "params = grid_search.cv_results_[\"params\"]\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" %(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our best model (remember we set refit=True?)\n",
    "best_mlp_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56716ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKerasTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31501419",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp_model.fit(x_train, y_train, epochs = 20,\n",
    "                   validation_data = (x_test, y_test),\n",
    "                   callbacks = [PlotLossesKerasTF()], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b68b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain predictions\n",
    "predictions = best_mlp_model.predict(x_test)\n",
    "predictions = predictions.reshape(predictions.shape[0], 1)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09447d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now let's unscale the model's predictions to see real prices!\n",
    "predictions_unscaled = scaler_y.inverse_transform(y_test)\n",
    "predictions_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's unscale y_test to get the original values\n",
    "y_test_unscaled = scaler_y.inverse_transform(predictions)\n",
    "y_test_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, predictions))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032269ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_submission_file(best_mlp_model, df_teste, \"submission_files/redeNeuronal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6811ba",
   "metadata": {},
   "source": [
    "#### 5.4 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a894259",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['incidents'], axis=1)\n",
    "\n",
    "y = df['incidents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(x)\n",
    "#scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(y)\n",
    "#x_scaled = pd.DataFrame(scaler_X.transform(x[x.columns]), columns=x.columns)\n",
    "#y_scaled = pd.DataFrame(scaler_y.transform(y[y.columns]), columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e84c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_submission_file(rfc, df_teste, \"submission_files/randomForestClassifier.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790026dd",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "* Verificar Logistic Regression\n",
    "* Verificar Redes Neuronais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61163e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
